---
title: "Introduction to RcppNT2"
author: "Kevin Ushey"
license: GPL (>= 2)
tags: nt2 simd parallel
summary: Introduction to NT2 with RcppNT2
---

Modern CPU processors are built with new, extended
instruction sets that optimize for certain operations. A
class of these allow for vectorized operations, called
Single Instruction / Multiple Data (SIMD) instructions. 
Although modern compilers will use these instructions when
possible, they are often unable to reason about whether or
not a particular block of code can be executed using SIMD
instructions.

The [**Numeric Template Toolbox**](https://github.com/jfalcou/nt2)
(**NT<sub>2</sub>**) is a an open-source C++ library that
makes it possible to explicitly request the use of SIMD
instructions when possible, while falling back to regular
scalar operations when not. 
[`RcppNT2`](http://rcppcore.github.io/RcppNT2/) wraps and
exposes this library for use with `R` vectors.

The primary abstraction that **NT<sub>2</sub>** uses under the 
hood is the `boost::simd::pack<>` data structure. This item 
represents a small, contiguous, pack of integral objects 
(e.g. `double`s), and comes with a host of functions that 
facilitate the use of SIMD operations on those objects when 
possible. Although you don't need to know the details to use
the high-level functionality provided, it's useful for
understanding what happens behind the scenes.

Here's a quick example of how we might compute the sum of 
elements in a vector, using **NT<sub>2</sub>**:

```{r, engine='Rcpp'}
// [[Rcpp::depends(RcppNT2)]]
#include <RcppNT2.h>
using namespace RcppNT2;

#include <Rcpp.h>
using namespace Rcpp;

// Define a functor -- a C++ class which defines a templated
// 'function call' operator -- to perform the addition of 
// two pieces of data.
struct add_two {
  template <typename T>
  T operator()(const T& lhs, const T& rhs) {
    return lhs + rhs;
  }
};

// [[Rcpp::export]]
double simd_sum(NumericVector x) {
  // Pass the functor to 'simdReduce()'.
  return simdReduce(x.begin(), x.end(), 0.0, add_two());
}
```

Behind the scenes, `simdReduce()` takes care of iteration 
over our sequence, and ensures that we use optimized SIMD 
instructions over packs of numbers when possible, and scalar
instructions when not. By passing a templated functor, 
`simdReduce()` can automagically choose the correct template
specialization depending on whether it's working with a pack
or not. In other words, two template specializations will be
generated in this case: one with `T = double`, and another
with `T = boost::simd::pack<double>`.

Let's confirm that this produces the correct output, and run
a small benchmark.

```{r}
# helper function for printing microbenchmark output
printBm <- function(bm) {
  summary <- summary(bm)
  print(summary[, 1:7], row.names = FALSE)
}

# generate some data
data <- rnorm(1024 * 1000)

# verify that it produces the correct sum
all.equal(simd_sum(data), sum(data))

# compare results
library(microbenchmark)
bm <- microbenchmark(sum(data), simd_sum(data))
printBm(bm)
```

We get a noticable gain by taking advantage of SIMD 
instructions here, although it's worth noting that we don't
handle `NA` and `NaN` with the same granularity as `R`.

## SIMD Algorithms

**NT<sub>2</sub>** provides two primary abstractions for the
implementation of SIMD algorithms:

| Algorithm                   | Transformation       |
|-----------------------------|----------------------|
| `boost::simd::transform()`  | `vector` -> `vector` |
| `boost::simd::accumulate()` | `vector` -> `scalar` |

These functions operate like their `std::` counterparts, but
expect a functor with a templated call operator. By making 
the call operator templated, **NT<sub>2</sub>** can generate
code using its own optimized SIMD functions when
appropriate, and fall back to a default implementation
(based on the integral types provided) when not.

`RcppNT2` augments this with its own algorithms as well:

| Algorithm                       | Transformation       |
|---------------------------------|----------------------|
| `RcppNT2::simdTransform()` | `vector` -> `vector` |
| `RcppNT2::simdReduce()`    | `vector` -> `scalar` |
| `RcppNT2::simdFor()`       | `vector` -> `any`    |

`simdFor()` is useful in particular when neither `transform()`
nor `accumulate()` seem to be a good fit.

## Writing SIMD-aware Algorithms

To take advantage of **NT<sub>2</sub>**, you should try to
perform the following steps:

1. Decompose your problem into separate, vectorizable pieces,
2. Select an appropriate algorithm provided by `RcppNT2`,
3. Write templated functors in a `SIMD`-aware way.

**NT<sub>2</sub>** provides a large number of functions that
have optimized specializations for packed data structures,
while falling back to regular operations for scalar data
structures. These functions can typically be accessed within
the `nt2` namespace. To illustrate, here's an example of a
functor that computes the square for a set of data, using
the `nt2::sqr()` function:

```{r, engine='Rcpp', eval=FALSE}
class simd_square {
template <typename T>
void operator()(const T& data) {
  return nt2::sqr(data);
}
};
```

A reference guide for other functions provided is available 
[here](http://nt2.metascale.fr/doc/html/user_manual0.html).

## Using RcppNT2 in an R Package

To build an R package that uses RcppNT2, you need to
add the following to your `DESCRIPTION` file:

```yaml
LinkingTo: RcppNT2, BH
SystemRequirements: C++11
```

## Learning More

If you want to dive deeper into **NT<sub>2</sub>**, you can
[read the online documentation](http://nt2.metascale.fr/doc/html/index.html).
